{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e7f23ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0c4f7b",
   "metadata": {},
   "source": [
    "# 数据操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "900cc0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12)\n",
    "x  # 向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c07eaf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape   # 维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa28d980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numel()   # 元素的种类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "338d9145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape((3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8749166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47b10d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[2,3,4],[1,2,3],[7,8,9]]).shape     # 通过python列表创建张量数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc18ddd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2.,  6., 10., 14., 18.]),\n",
       " tensor([ 0., -2., -2.,  0.,  0.]),\n",
       " tensor([ 1.,  8., 24., 49., 81.]),\n",
       " tensor([1.0000, 0.5000, 0.6667, 1.0000, 1.0000]),\n",
       " tensor([1.0000e+00, 1.6000e+01, 4.0960e+03, 8.2354e+05, 3.8742e+08]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 进行\n",
    "x = torch.tensor([1,2,4,7,9.0])    \n",
    "y = torch.tensor([1,4,6,7,9])         \n",
    "x+y, x-y, x*y, x/y, x**y                          #算术运算符（+，-，*，/，**）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b06f62c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 1.,  2.,  3.,  4.],\n",
       "         [ 2.,  4.,  5.,  6.],\n",
       "         [ 8.,  9.,  9.,  7.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  1.,  2.,  3.,  4.],\n",
       "         [ 4.,  5.,  6.,  7.,  2.,  4.,  5.,  6.],\n",
       "         [ 8.,  9., 10., 11.,  8.,  9.,  9.,  7.]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(12,dtype=torch.float32).reshape((3,4))\n",
    "Y = torch.tensor([[1,2,3,4],[2.0,4,5,6],[8,9,9,7]])\n",
    "torch.cat((X,Y),dim=0),torch.cat((X,Y),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f511e4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [ True,  True, False, False]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X==Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff7b9565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(66.)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7803b6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 广播机制进行元素操作  维度一样\n",
    "x = torch.arange(3).reshape((3,1))\n",
    "y = torch.arange(2).reshape((1,2))\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e11f8c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13cfa2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 8.,  9., 10., 11.]),\n",
       " tensor([[ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[-1],X[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d777e044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  9.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1,2] = 9\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f26cce32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 运行一些操作会导致新结果分配内存\n",
    "before = id(Y)\n",
    "Y = Y+X\n",
    "id(Y) == before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8b7dd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id(Z) 2415044108720\n",
      "id(Z) 2415044108720\n"
     ]
    }
   ],
   "source": [
    "# 原地操作\n",
    "Z = torch.zeros_like(Y)\n",
    "print('id(Z)',id(Z))\n",
    "Z[:] = Y+X\n",
    "print('id(Z)',id(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c415e581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(X)\n",
    "X += Y\n",
    "id(X) == before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9030d5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, torch.Tensor)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = X.numpy()\n",
    "B = torch.tensor(A)\n",
    "type(A), type(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f153a848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.5000]), 3.5, 3.5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([3.5])\n",
    "a, a.item(), float(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aae9ff7",
   "metadata": {},
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1450d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83e20364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\data\\\\house_tiny.csv'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个人工数据集，并存储在csv（逗号分隔符）文件 ../data/house_tiny.csv中。以其他格式存储的数据也可以通过类似的方式进行处理\n",
    "os.makedirs(os.path.join('..','data'),exist_ok=True)\n",
    "data_file = os.path.join('..','data','house_tiny.csv')\n",
    "with open(data_file,'w') as f:\n",
    "    f.write('NumRooms, Alley, Price\\n')  #列名\n",
    "    f.write('NA, Pave, 127500\\n')   # 每行表示一个数据样本\n",
    "    f.write('2, NA, 106000\\n') \n",
    "    f.write('4, NA, 178100\\n')\n",
    "    f.write('NA, NA, 140000\\n')\n",
    "data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33cc0c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c3046a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumRooms</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Pave</td>\n",
       "      <td>127500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>178100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NumRooms  Alley   Price\n",
       "0       NaN   Pave  127500\n",
       "1       2.0     NA  106000\n",
       "2       4.0     NA  178100\n",
       "3       NaN     NA  140000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ef21c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  Alley\n",
      "0       3.0   Pave\n",
      "1       2.0     NA\n",
      "2       4.0     NA\n",
      "3       3.0     NA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h2220\\AppData\\Local\\Temp\\ipykernel_17488\\961750372.py:3: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  inputs = inputs.fillna(inputs.mean())\n"
     ]
    }
   ],
   "source": [
    "# 通过位置索引iloc，我们将data分成inputs和outputs， 其中前者为data的前两列，而后者为data的最后一列。 对于inputs中缺少的数值，我们用同一列的均值替换“NaN”项\n",
    "inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n",
    "inputs = inputs.fillna(inputs.mean())\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "879d2524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms   Alley_ NA   Alley_ Pave   Alley_nan\n",
      "0       3.0           0             1           0\n",
      "1       2.0           1             0           0\n",
      "2       4.0           1             0           0\n",
      "3       3.0           1             0           0\n"
     ]
    }
   ],
   "source": [
    "# 对于inputs中的类别值或离散值，我们将“NaN”视为一个类别。 由于“巷子类型”（“Alley”）列只接受两种类型的类别值“Pave”和“NaN”， pandas可以自动将此列转换为两列“Alley_Pave”和“Alley_nan”。 巷子类型为“Pave”的行会将“Alley_Pave”的值设置为1，“Alley_nan”的值设置为0。 缺少巷子类型的行会将“Alley_Pave”和“Alley_nan”分别设置为0和1\n",
    "inputs1 = pd.get_dummies(inputs, dummy_na=True)\n",
    "print(inputs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9cabfed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms   Alley_ NA   Alley_ Pave\n",
      "0       3.0           0             1\n",
      "1       2.0           1             0\n",
      "2       4.0           1             0\n",
      "3       3.0           1             0\n"
     ]
    }
   ],
   "source": [
    "inputs2 = pd.get_dummies(inputs)\n",
    "print(inputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f7fd10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 0., 1.],\n",
       "         [2., 1., 0.],\n",
       "         [4., 1., 0.],\n",
       "         [3., 1., 0.]], dtype=torch.float64),\n",
       " tensor([127500, 106000, 178100, 140000]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = torch.tensor(inputs2.values), torch.tensor(outputs.values)\n",
    "X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9c6e98",
   "metadata": {},
   "source": [
    "# 线性代数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f960f7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20).reshape((5,4))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48c0110d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  4,  8, 12, 16],\n",
       "        [ 1,  5,  9, 13, 17],\n",
       "        [ 2,  6, 10, 14, 18],\n",
       "        [ 3,  7, 11, 15, 19]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97f88751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对称矩阵\n",
    "B = torch.tensor([[1,2,3],[2,0,4],[3,4,0]])\n",
    "B == B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ae28e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[ 0.,  2.,  4.,  6.],\n",
       "         [ 8., 10., 12., 14.],\n",
       "         [16., 18., 20., 22.],\n",
       "         [24., 26., 28., 30.],\n",
       "         [32., 34., 36., 38.]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20, dtype = torch.float32).reshape((5,4))\n",
    "B = A.clone()\n",
    "A, A+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f717ec7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2415055510544, 2415055508304, 2415055506064)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(A),id(A+B),id(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b2047ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   1.,   4.,   9.],\n",
       "        [ 16.,  25.,  36.,  49.],\n",
       "        [ 64.,  81., 100., 121.],\n",
       "        [144., 169., 196., 225.],\n",
       "        [256., 289., 324., 361.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 两个矩阵的按元素乘法称为Hadamard积（Hadamard product）（数学符号）\n",
    "A*B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3795c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2.,  3.,  4.,  5.],\n",
       "         [ 6.,  7.,  8.,  9.],\n",
       "         [10., 11., 12., 13.],\n",
       "         [14., 15., 16., 17.],\n",
       "         [18., 19., 20., 21.]]),\n",
       " tensor([[ 0.,  2.,  4.,  6.],\n",
       "         [ 8., 10., 12., 14.],\n",
       "         [16., 18., 20., 22.],\n",
       "         [24., 26., 28., 30.],\n",
       "         [32., 34., 36., 38.]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将张量乘以或加上一个标量不会改变张量的形状，其中张量的每个元素都将与标量相加或相乘。\n",
    "a = 2\n",
    "a + A, a*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "209a1a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca8941f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5, 4]), tensor(780.))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20*2, dtype = torch.float32).reshape((2, 5, 4))\n",
    "A.shape,A.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc72c681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]],\n",
       "\n",
       "        [[20., 21., 22., 23.],\n",
       "         [24., 25., 26., 27.],\n",
       "         [28., 29., 30., 31.],\n",
       "         [32., 33., 34., 35.],\n",
       "         [36., 37., 38., 39.]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b4d4110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[20., 22., 24., 26.],\n",
       "         [28., 30., 32., 34.],\n",
       "         [36., 38., 40., 42.],\n",
       "         [44., 46., 48., 50.],\n",
       "         [52., 54., 56., 58.]]),\n",
       " torch.Size([5, 4]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sum_axis0 = A.sum(axis=0)   # 对第一个维度求和，其他维不变\n",
    "A_sum_axis0, A_sum_axis0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa7f8cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 40.,  45.,  50.,  55.],\n",
       "         [140., 145., 150., 155.]]),\n",
       " torch.Size([2, 4]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sum_axis1 = A.sum(axis=1)   # 对第二个维度求和，其他维不变\n",
    "A_sum_axis1, A_sum_axis1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c37bb60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  6.,  22.,  38.,  54.,  70.],\n",
       "         [ 86., 102., 118., 134., 150.]]),\n",
       " torch.Size([2, 5]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sum_axis2 = A.sum(axis=2)   # 对第三个维度求和，其他维不变\n",
    "A_sum_axis2, A_sum_axis2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7f0986e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([180., 190., 200., 210.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a212d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(19.5000), tensor(19.5000))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 求均值，相当于先求和再/元素个数\n",
    "A.mean(), A.sum() / A.numel()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b63cb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[10., 11., 12., 13.],\n",
       "         [14., 15., 16., 17.],\n",
       "         [18., 19., 20., 21.],\n",
       "         [22., 23., 24., 25.],\n",
       "         [26., 27., 28., 29.]]),\n",
       " tensor([[10., 11., 12., 13.],\n",
       "         [14., 15., 16., 17.],\n",
       "         [18., 19., 20., 21.],\n",
       "         [22., 23., 24., 25.],\n",
       "         [26., 27., 28., 29.]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(axis=0), A.sum(axis=0) / A.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b627eeeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 40.,  45.,  50.,  55.]],\n",
       "\n",
       "        [[140., 145., 150., 155.]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 有时在调用函数来计算总和或均值时保持轴数不变会很有用。\n",
    "sum_A = A.sum(axis = 1, keepdims = True)\n",
    "sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06ae9259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0222, 0.0400, 0.0545],\n",
       "         [0.1000, 0.1111, 0.1200, 0.1273],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.3000, 0.2889, 0.2800, 0.2727],\n",
       "         [0.4000, 0.3778, 0.3600, 0.3455]],\n",
       "\n",
       "        [[0.1429, 0.1448, 0.1467, 0.1484],\n",
       "         [0.1714, 0.1724, 0.1733, 0.1742],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.2286, 0.2276, 0.2267, 0.2258],\n",
       "         [0.2571, 0.2552, 0.2533, 0.2516]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 例如：由于sum_A在对每行进行求和后仍保持两个轴，我们可以通过广播将A除以sum_A。\n",
    "A / sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93659d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.,   1.,   2.,   3.],\n",
       "         [  4.,   6.,   8.,  10.],\n",
       "         [ 12.,  15.,  18.,  21.],\n",
       "         [ 24.,  28.,  32.,  36.],\n",
       "         [ 40.,  45.,  50.,  55.]],\n",
       "\n",
       "        [[ 20.,  21.,  22.,  23.],\n",
       "         [ 44.,  46.,  48.,  50.],\n",
       "         [ 72.,  75.,  78.,  81.],\n",
       "         [104., 108., 112., 116.],\n",
       "         [140., 145., 150., 155.]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果我们想沿某个轴计算A元素的累积总和， 比如axis=0（按行计算），我们可以调用cumsum函数。 此函数不会沿任何轴降低输入张量的维度\n",
    "A.cumsum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c6d373f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.), tensor(6.))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 另一个最基本的操作之一是点积。 给定两个向量， 它们的点积（dot product） （或） 是相同位置的按元素乘积的和：\n",
    "y = torch.ones(4,dtype = torch.float32)\n",
    "x = torch.tensor([0., 1., 2., 3.])\n",
    "x, y, torch.dot(x, y),torch.sum(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "85b34f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([0., 1., 2., 3.]),\n",
       " torch.Size([5, 4]),\n",
       " torch.Size([4]),\n",
       " tensor([ 14.,  38.,  62.,  86., 110.]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵向量乘积，其中每个ai都是行向量，表示矩阵的第i行。 A为m*n的矩阵，x为n维列向量，矩阵向量积Ax是一个长度为m的列向量， 其第i个元素是点积ai·x\n",
    "A1 = torch.arange(20,dtype = torch.float32).reshape((5,4))\n",
    "A1, x, A1.shape, x.shape,torch.mv(A1,x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7384980b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]),\n",
       " tensor([[ 6.,  6.,  6.],\n",
       "         [22., 22., 22.],\n",
       "         [38., 38., 38.],\n",
       "         [54., 54., 54.],\n",
       "         [70., 70., 70.]]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵-矩阵乘法,用行向量ai表示矩阵A1的第i行，并让列向量bj作为矩阵B的第j列。要生成矩阵积C = A·B，最简单的方法是考虑的行向量和的列向量:每个元素cij计算为行向量ai与列向量bj点积\n",
    "B = torch.ones((4,3))\n",
    "A1, B, torch.mm(A1,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "864535bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L2 范数\n",
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2b6e7348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L1范数\n",
    "torch.abs(u).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ad55cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵F范数\n",
    "torch.norm(torch.ones((4,9)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d3a6bb",
   "metadata": {},
   "source": [
    "# 自动求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0a06e8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4.0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6f43e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在计算y关于x的梯度之前，我们需要一个地方来储存梯度\n",
    "x.requires_grad_(True)   # 等价于 x = torch.arange(4.0, requires_grad = True)\n",
    "x.grad  # 默认值是None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "702b9891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 2 * torch.dot(x, x)  # 内积\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe61ce51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用反向传播函数来自动计算y关于x每个分量的梯度\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "60db18bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == x * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f0662b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  在默认情况下，pytorch会累积梯度，我们需要清除之前的值\n",
    "x.grad.zero_()\n",
    "y = x.sum()\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e088a206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对非标量调用‘backward’需要传入一个‘gradient’参数，该参数指定微分函数\n",
    "x.grad.zero_()\n",
    "y = x*x   # 矩阵\n",
    "# 等价于y.backward(torch.ones(len(x)))\n",
    "y.sum().backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2fb77675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将某些计算移动到记录的计算图之外\n",
    "x.grad.zero_()\n",
    "y = x*x\n",
    "u = y.detach()   #将y变为一个常数赋予u\n",
    "z = u * x\n",
    "\n",
    "z.sum().backward()\n",
    "x.grad == u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b7d5ffe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y.sum().backward()\n",
    "x.grad == 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5aff8ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 即使构建函数的计算图需要通过Python控制流（例如，条件、循环或任意函数调用），我们仍然可以计算得到的变量的梯度\n",
    "def f(a):\n",
    "    b = a * 2\n",
    "    while b.norm() < 1000:\n",
    "        b = b * 2\n",
    "    if b.sum() > 0:\n",
    "        c = b\n",
    "    else:\n",
    "        c = 100 * b\n",
    "    return c\n",
    "a = torch.randn(size = (),requires_grad=True)\n",
    "d = f(a)\n",
    "d.backward()\n",
    "a.grad == d/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a930bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
